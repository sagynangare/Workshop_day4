{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "paragraph =  \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
       " 'Yet we have not done this to any other nation.',\n",
       " 'We have not conquered anyone.',\n",
       " 'We have not grabbed their land, their culture, \\n               their history and tried to enforce our way of life on them.',\n",
       " 'Why?',\n",
       " 'Because we respect the freedom of others.That is why my \\n               first vision is that of freedom.',\n",
       " 'I believe that India got its first vision of \\n               this in 1857, when we started the War of Independence.',\n",
       " 'It is this freedom that\\n               we must protect and nurture and build on.',\n",
       " 'If we are not free, no one will respect us.',\n",
       " 'My second vision for India’s development.',\n",
       " 'For fifty years we have been a developing nation.',\n",
       " 'It is time we see ourselves as a developed nation.',\n",
       " 'We are among the top 5 nations of the world\\n               in terms of GDP.',\n",
       " 'We have a 10 percent growth rate in most areas.',\n",
       " 'Our poverty levels are falling.',\n",
       " 'Our achievements are being globally recognised today.',\n",
       " 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.',\n",
       " 'Isn’t this incorrect?',\n",
       " 'I have a third vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that unless India \\n               stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be \\n               strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of \\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.',\n",
       " 'I see four milestones in my career']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)#line split\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()#tokens/words\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)#list to str\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three vision india'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I three vision india .',\n",
       " 'In 3000 year histori , peopl world come invad us , captur land , conquer mind .',\n",
       " 'from alexand onward , greek , turk , mogul , portugues , british , french , dutch , came loot us , took .',\n",
       " 'yet done nation .',\n",
       " 'We conquer anyon .',\n",
       " 'We grab land , cultur , histori tri enforc way life .',\n",
       " 'whi ?',\n",
       " 'becaus respect freedom others.that first vision freedom .',\n",
       " 'I believ india got first vision 1857 , start war independ .',\n",
       " 'It freedom must protect nurtur build .',\n",
       " 'If free , one respect us .',\n",
       " 'My second vision india ’ develop .',\n",
       " 'for fifti year develop nation .',\n",
       " 'It time see develop nation .',\n",
       " 'We among top 5 nation world term gdp .',\n",
       " 'We 10 percent growth rate area .',\n",
       " 'our poverti level fall .',\n",
       " 'our achiev global recognis today .',\n",
       " 'yet lack self-confid see develop nation , self-reli self-assur .',\n",
       " 'isn ’ incorrect ?',\n",
       " 'I third vision .',\n",
       " 'india must stand world .',\n",
       " 'becaus I believ unless india stand world , one respect us .',\n",
       " 'onli strength respect strength .',\n",
       " 'We must strong militari power also econom power .',\n",
       " 'both must go hand-in-hand .',\n",
       " 'My good fortun work three great mind .',\n",
       " 'dr. vikram sarabhai dept .',\n",
       " 'space , professor satish dhawan , succeed dr. brahm prakash , father nuclear materi .',\n",
       " 'I lucki work three close consid great opportun life .',\n",
       " 'I see four mileston career']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I three vision India .',\n",
       " 'In 3000 year history , people world come invaded u , captured land , conquered mind .',\n",
       " 'From Alexander onwards , Greeks , Turks , Moguls , Portuguese , British , French , Dutch , came looted u , took .',\n",
       " 'Yet done nation .',\n",
       " 'We conquered anyone .',\n",
       " 'We grabbed land , culture , history tried enforce way life .',\n",
       " 'Why ?',\n",
       " 'Because respect freedom others.That first vision freedom .',\n",
       " 'I believe India got first vision 1857 , started War Independence .',\n",
       " 'It freedom must protect nurture build .',\n",
       " 'If free , one respect u .',\n",
       " 'My second vision India ’ development .',\n",
       " 'For fifty year developing nation .',\n",
       " 'It time see developed nation .',\n",
       " 'We among top 5 nation world term GDP .',\n",
       " 'We 10 percent growth rate area .',\n",
       " 'Our poverty level falling .',\n",
       " 'Our achievement globally recognised today .',\n",
       " 'Yet lack self-confidence see developed nation , self-reliant self-assured .',\n",
       " 'Isn ’ incorrect ?',\n",
       " 'I third vision .',\n",
       " 'India must stand world .',\n",
       " 'Because I believe unless India stand world , one respect u .',\n",
       " 'Only strength respect strength .',\n",
       " 'We must strong military power also economic power .',\n",
       " 'Both must go hand-in-hand .',\n",
       " 'My good fortune worked three great mind .',\n",
       " 'Dr. Vikram Sarabhai Dept .',\n",
       " 'space , Professor Satish Dhawan , succeeded Dr. Brahm Prakash , father nuclear material .',\n",
       " 'I lucky worked three closely consider great opportunity life .',\n",
       " 'I see four milestone career']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatization\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india',\n",
       " 'year history people world come invaded u captured land conquered mind',\n",
       " 'alexander onwards greek turk mogul portuguese british french dutch came looted u took',\n",
       " 'yet done nation',\n",
       " 'conquered anyone',\n",
       " 'grabbed land culture history tried enforce way life',\n",
       " '',\n",
       " 'respect freedom others first vision freedom',\n",
       " 'believe india got first vision started war independence',\n",
       " 'freedom must protect nurture build',\n",
       " 'free one respect u',\n",
       " 'second vision india development',\n",
       " 'fifty year developing nation',\n",
       " 'time see developed nation',\n",
       " 'among top nation world term gdp',\n",
       " 'percent growth rate area',\n",
       " 'poverty level falling',\n",
       " 'achievement globally recognised today',\n",
       " 'yet lack self confidence see developed nation self reliant self assured',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believe unless india stand world one respect u',\n",
       " 'strength respect strength',\n",
       " 'must strong military power also economic power',\n",
       " 'must go hand hand',\n",
       " 'good fortune worked three great mind',\n",
       " 'dr vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeeded dr brahm prakash father nuclear material',\n",
       " 'lucky worked three closely consider great opportunity life',\n",
       " 'see four milestone career']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.25883507, 0.30512561,\n",
       "        0.        ],\n",
       "       [0.        , 0.28867513, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)# replacing all the digits from dataset to whitespaces\n",
    "\n",
    "text = re.sub(r'\\s+',' ',text)#\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have three visions for india. in years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. from alexander onwards, the greeks, the turks, the moguls, the portuguese, the british, the french, the dutch, all of them came and looted us, took over what was ours. yet we have not done this to any other nation. we have not conquered anyone. we have not grabbed their land, their culture, their history and tried to enforce our way of life on them. why? because we respect the freedom of others.that is why my first vision is that of freedom. i believe that india got its first vision of this in , when we started the war of independence. it is this freedom that we must protect and nurture and build on. if we are not free, no one will respect us. my second vision for india’s development. for fifty years we have been a developing nation. it is time we see ourselves as a developed nation. we are among the top nations of the world in terms of gdp. we have a percent growth rate in most areas. our poverty levels are falling. our achievements are being globally recognised today. yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured. isn’t this incorrect? i have a third vision. india must stand up to the world. because i believe that unless india stands up to the world, no one will respect us. only strength respects strength. we must be strong not only as a military power but also as an economic power. both must go hand-in-hand. my good fortune was to have worked with three great minds. dr. vikram sarabhai of the dept. of space, professor satish dhawan, who succeeded him and dr. brahm prakash, father of nuclear material. i was lucky to have worked with all three of them closely and consider this the great opportunity of my life. i see four milestones in my career'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['three', 'visions', 'india', '.'],\n",
       " ['years',\n",
       "  'history',\n",
       "  ',',\n",
       "  'people',\n",
       "  'world',\n",
       "  'come',\n",
       "  'invaded',\n",
       "  'us',\n",
       "  ',',\n",
       "  'captured',\n",
       "  'lands',\n",
       "  ',',\n",
       "  'conquered',\n",
       "  'minds',\n",
       "  '.'],\n",
       " ['alexander',\n",
       "  'onwards',\n",
       "  ',',\n",
       "  'greeks',\n",
       "  ',',\n",
       "  'turks',\n",
       "  ',',\n",
       "  'moguls',\n",
       "  ',',\n",
       "  'portuguese',\n",
       "  ',',\n",
       "  'british',\n",
       "  ',',\n",
       "  'french',\n",
       "  ',',\n",
       "  'dutch',\n",
       "  ',',\n",
       "  'came',\n",
       "  'looted',\n",
       "  'us',\n",
       "  ',',\n",
       "  'took',\n",
       "  '.'],\n",
       " ['yet', 'done', 'nation', '.'],\n",
       " ['conquered', 'anyone', '.'],\n",
       " ['grabbed',\n",
       "  'land',\n",
       "  ',',\n",
       "  'culture',\n",
       "  ',',\n",
       "  'history',\n",
       "  'tried',\n",
       "  'enforce',\n",
       "  'way',\n",
       "  'life',\n",
       "  '.'],\n",
       " ['?'],\n",
       " ['respect', 'freedom', 'others.that', 'first', 'vision', 'freedom', '.'],\n",
       " ['believe',\n",
       "  'india',\n",
       "  'got',\n",
       "  'first',\n",
       "  'vision',\n",
       "  ',',\n",
       "  'started',\n",
       "  'war',\n",
       "  'independence',\n",
       "  '.'],\n",
       " ['freedom', 'must', 'protect', 'nurture', 'build', '.'],\n",
       " ['free', ',', 'one', 'respect', 'us', '.'],\n",
       " ['second', 'vision', 'india', '’', 'development', '.'],\n",
       " ['fifty', 'years', 'developing', 'nation', '.'],\n",
       " ['time', 'see', 'developed', 'nation', '.'],\n",
       " ['among', 'top', 'nations', 'world', 'terms', 'gdp', '.'],\n",
       " ['percent', 'growth', 'rate', 'areas', '.'],\n",
       " ['poverty', 'levels', 'falling', '.'],\n",
       " ['achievements', 'globally', 'recognised', 'today', '.'],\n",
       " ['yet',\n",
       "  'lack',\n",
       "  'self-confidence',\n",
       "  'see',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  ',',\n",
       "  'self-reliant',\n",
       "  'self-assured',\n",
       "  '.'],\n",
       " ['’', 'incorrect', '?'],\n",
       " ['third', 'vision', '.'],\n",
       " ['india', 'must', 'stand', 'world', '.'],\n",
       " ['believe',\n",
       "  'unless',\n",
       "  'india',\n",
       "  'stands',\n",
       "  'world',\n",
       "  ',',\n",
       "  'one',\n",
       "  'respect',\n",
       "  'us',\n",
       "  '.'],\n",
       " ['strength', 'respects', 'strength', '.'],\n",
       " ['must', 'strong', 'military', 'power', 'also', 'economic', 'power', '.'],\n",
       " ['must', 'go', 'hand-in-hand', '.'],\n",
       " ['good', 'fortune', 'worked', 'three', 'great', 'minds', '.'],\n",
       " ['dr.', 'vikram', 'sarabhai', 'dept', '.'],\n",
       " ['space',\n",
       "  ',',\n",
       "  'professor',\n",
       "  'satish',\n",
       "  'dhawan',\n",
       "  ',',\n",
       "  'succeeded',\n",
       "  'dr.',\n",
       "  'brahm',\n",
       "  'prakash',\n",
       "  ',',\n",
       "  'father',\n",
       "  'nuclear',\n",
       "  'material',\n",
       "  '.'],\n",
       " ['lucky',\n",
       "  'worked',\n",
       "  'three',\n",
       "  'closely',\n",
       "  'consider',\n",
       "  'great',\n",
       "  'opportunity',\n",
       "  'life',\n",
       "  '.'],\n",
       " ['see', 'four', 'milestones', 'career']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]\n",
    "    \n",
    "    \n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'three': <gensim.models.keyedvectors.Vocab at 0x276ee91bb88>,\n",
       " 'visions': <gensim.models.keyedvectors.Vocab at 0x276ee91d488>,\n",
       " 'india': <gensim.models.keyedvectors.Vocab at 0x276eeaa4b88>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x276eeb3d9c8>,\n",
       " 'years': <gensim.models.keyedvectors.Vocab at 0x276eeb62188>,\n",
       " 'history': <gensim.models.keyedvectors.Vocab at 0x276eeb622c8>,\n",
       " ',': <gensim.models.keyedvectors.Vocab at 0x276eeb62308>,\n",
       " 'people': <gensim.models.keyedvectors.Vocab at 0x276eeb62348>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x276eeb3da88>,\n",
       " 'come': <gensim.models.keyedvectors.Vocab at 0x276eeb62288>,\n",
       " 'invaded': <gensim.models.keyedvectors.Vocab at 0x276eeb62388>,\n",
       " 'us': <gensim.models.keyedvectors.Vocab at 0x276eeb623c8>,\n",
       " 'captured': <gensim.models.keyedvectors.Vocab at 0x276eeb62408>,\n",
       " 'lands': <gensim.models.keyedvectors.Vocab at 0x276eeb62448>,\n",
       " 'conquered': <gensim.models.keyedvectors.Vocab at 0x276eeb62488>,\n",
       " 'minds': <gensim.models.keyedvectors.Vocab at 0x276eeb624c8>,\n",
       " 'alexander': <gensim.models.keyedvectors.Vocab at 0x276eeb62508>,\n",
       " 'onwards': <gensim.models.keyedvectors.Vocab at 0x276eeb62548>,\n",
       " 'greeks': <gensim.models.keyedvectors.Vocab at 0x276eeb62588>,\n",
       " 'turks': <gensim.models.keyedvectors.Vocab at 0x276eeb625c8>,\n",
       " 'moguls': <gensim.models.keyedvectors.Vocab at 0x276eeb62608>,\n",
       " 'portuguese': <gensim.models.keyedvectors.Vocab at 0x276eeb62648>,\n",
       " 'british': <gensim.models.keyedvectors.Vocab at 0x276eeb62688>,\n",
       " 'french': <gensim.models.keyedvectors.Vocab at 0x276eeb626c8>,\n",
       " 'dutch': <gensim.models.keyedvectors.Vocab at 0x276eeb62708>,\n",
       " 'came': <gensim.models.keyedvectors.Vocab at 0x276eeb62748>,\n",
       " 'looted': <gensim.models.keyedvectors.Vocab at 0x276eeb62788>,\n",
       " 'took': <gensim.models.keyedvectors.Vocab at 0x276eeb627c8>,\n",
       " 'yet': <gensim.models.keyedvectors.Vocab at 0x276eeb62808>,\n",
       " 'done': <gensim.models.keyedvectors.Vocab at 0x276eeb62848>,\n",
       " 'nation': <gensim.models.keyedvectors.Vocab at 0x276eeb62888>,\n",
       " 'anyone': <gensim.models.keyedvectors.Vocab at 0x276eeb628c8>,\n",
       " 'grabbed': <gensim.models.keyedvectors.Vocab at 0x276eeb62908>,\n",
       " 'land': <gensim.models.keyedvectors.Vocab at 0x276eeb62948>,\n",
       " 'culture': <gensim.models.keyedvectors.Vocab at 0x276eeb62988>,\n",
       " 'tried': <gensim.models.keyedvectors.Vocab at 0x276eeb629c8>,\n",
       " 'enforce': <gensim.models.keyedvectors.Vocab at 0x276eeb62a08>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x276eeb62a48>,\n",
       " 'life': <gensim.models.keyedvectors.Vocab at 0x276eeb62a88>,\n",
       " '?': <gensim.models.keyedvectors.Vocab at 0x276eeb62ac8>,\n",
       " 'respect': <gensim.models.keyedvectors.Vocab at 0x276eeb62b08>,\n",
       " 'freedom': <gensim.models.keyedvectors.Vocab at 0x276eeb62b48>,\n",
       " 'others.that': <gensim.models.keyedvectors.Vocab at 0x276eeb62b88>,\n",
       " 'first': <gensim.models.keyedvectors.Vocab at 0x276eeb62bc8>,\n",
       " 'vision': <gensim.models.keyedvectors.Vocab at 0x276eeb62c08>,\n",
       " 'believe': <gensim.models.keyedvectors.Vocab at 0x276eeb62c48>,\n",
       " 'got': <gensim.models.keyedvectors.Vocab at 0x276eeb62c88>,\n",
       " 'started': <gensim.models.keyedvectors.Vocab at 0x276eeb62cc8>,\n",
       " 'war': <gensim.models.keyedvectors.Vocab at 0x276eeb62d08>,\n",
       " 'independence': <gensim.models.keyedvectors.Vocab at 0x276eeb62d48>,\n",
       " 'must': <gensim.models.keyedvectors.Vocab at 0x276eeb62d88>,\n",
       " 'protect': <gensim.models.keyedvectors.Vocab at 0x276eeb62dc8>,\n",
       " 'nurture': <gensim.models.keyedvectors.Vocab at 0x276eeb62e08>,\n",
       " 'build': <gensim.models.keyedvectors.Vocab at 0x276eeb62e48>,\n",
       " 'free': <gensim.models.keyedvectors.Vocab at 0x276eeb62e88>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x276eeb62ec8>,\n",
       " 'second': <gensim.models.keyedvectors.Vocab at 0x276eeb62f08>,\n",
       " '’': <gensim.models.keyedvectors.Vocab at 0x276eeb62f48>,\n",
       " 'development': <gensim.models.keyedvectors.Vocab at 0x276eeb62f88>,\n",
       " 'fifty': <gensim.models.keyedvectors.Vocab at 0x276eeb62fc8>,\n",
       " 'developing': <gensim.models.keyedvectors.Vocab at 0x276eeb64048>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x276eeb64088>,\n",
       " 'see': <gensim.models.keyedvectors.Vocab at 0x276eeb640c8>,\n",
       " 'developed': <gensim.models.keyedvectors.Vocab at 0x276eeb64108>,\n",
       " 'among': <gensim.models.keyedvectors.Vocab at 0x276eeb64148>,\n",
       " 'top': <gensim.models.keyedvectors.Vocab at 0x276eeb64188>,\n",
       " 'nations': <gensim.models.keyedvectors.Vocab at 0x276eeb641c8>,\n",
       " 'terms': <gensim.models.keyedvectors.Vocab at 0x276eeb64208>,\n",
       " 'gdp': <gensim.models.keyedvectors.Vocab at 0x276eeb64248>,\n",
       " 'percent': <gensim.models.keyedvectors.Vocab at 0x276eeb64288>,\n",
       " 'growth': <gensim.models.keyedvectors.Vocab at 0x276eeb642c8>,\n",
       " 'rate': <gensim.models.keyedvectors.Vocab at 0x276eeb64308>,\n",
       " 'areas': <gensim.models.keyedvectors.Vocab at 0x276eeb64348>,\n",
       " 'poverty': <gensim.models.keyedvectors.Vocab at 0x276eeb64388>,\n",
       " 'levels': <gensim.models.keyedvectors.Vocab at 0x276eeb643c8>,\n",
       " 'falling': <gensim.models.keyedvectors.Vocab at 0x276eeb64408>,\n",
       " 'achievements': <gensim.models.keyedvectors.Vocab at 0x276eeb64448>,\n",
       " 'globally': <gensim.models.keyedvectors.Vocab at 0x276eeb64488>,\n",
       " 'recognised': <gensim.models.keyedvectors.Vocab at 0x276eeb644c8>,\n",
       " 'today': <gensim.models.keyedvectors.Vocab at 0x276eeb64508>,\n",
       " 'lack': <gensim.models.keyedvectors.Vocab at 0x276eeb64548>,\n",
       " 'self-confidence': <gensim.models.keyedvectors.Vocab at 0x276eeb64588>,\n",
       " 'self-reliant': <gensim.models.keyedvectors.Vocab at 0x276eeb645c8>,\n",
       " 'self-assured': <gensim.models.keyedvectors.Vocab at 0x276eeb64608>,\n",
       " 'incorrect': <gensim.models.keyedvectors.Vocab at 0x276eeb64648>,\n",
       " 'third': <gensim.models.keyedvectors.Vocab at 0x276eeb64688>,\n",
       " 'stand': <gensim.models.keyedvectors.Vocab at 0x276eeb646c8>,\n",
       " 'unless': <gensim.models.keyedvectors.Vocab at 0x276eeb64708>,\n",
       " 'stands': <gensim.models.keyedvectors.Vocab at 0x276eeb64748>,\n",
       " 'strength': <gensim.models.keyedvectors.Vocab at 0x276eeb64788>,\n",
       " 'respects': <gensim.models.keyedvectors.Vocab at 0x276eeb647c8>,\n",
       " 'strong': <gensim.models.keyedvectors.Vocab at 0x276eeb64808>,\n",
       " 'military': <gensim.models.keyedvectors.Vocab at 0x276eeb64848>,\n",
       " 'power': <gensim.models.keyedvectors.Vocab at 0x276eeb64888>,\n",
       " 'also': <gensim.models.keyedvectors.Vocab at 0x276eeb648c8>,\n",
       " 'economic': <gensim.models.keyedvectors.Vocab at 0x276eeb64908>,\n",
       " 'go': <gensim.models.keyedvectors.Vocab at 0x276eeb64948>,\n",
       " 'hand-in-hand': <gensim.models.keyedvectors.Vocab at 0x276eeb64988>,\n",
       " 'good': <gensim.models.keyedvectors.Vocab at 0x276eeb649c8>,\n",
       " 'fortune': <gensim.models.keyedvectors.Vocab at 0x276eeb64a08>,\n",
       " 'worked': <gensim.models.keyedvectors.Vocab at 0x276eeb64a48>,\n",
       " 'great': <gensim.models.keyedvectors.Vocab at 0x276eeb64a88>,\n",
       " 'dr.': <gensim.models.keyedvectors.Vocab at 0x276eeb64ac8>,\n",
       " 'vikram': <gensim.models.keyedvectors.Vocab at 0x276eeb64b08>,\n",
       " 'sarabhai': <gensim.models.keyedvectors.Vocab at 0x276eeb64b48>,\n",
       " 'dept': <gensim.models.keyedvectors.Vocab at 0x276eeb64b88>,\n",
       " 'space': <gensim.models.keyedvectors.Vocab at 0x276eeb64bc8>,\n",
       " 'professor': <gensim.models.keyedvectors.Vocab at 0x276eeb64c08>,\n",
       " 'satish': <gensim.models.keyedvectors.Vocab at 0x276eeb64c48>,\n",
       " 'dhawan': <gensim.models.keyedvectors.Vocab at 0x276eeb64c88>,\n",
       " 'succeeded': <gensim.models.keyedvectors.Vocab at 0x276eeb64cc8>,\n",
       " 'brahm': <gensim.models.keyedvectors.Vocab at 0x276eeb64d08>,\n",
       " 'prakash': <gensim.models.keyedvectors.Vocab at 0x276eeb64d48>,\n",
       " 'father': <gensim.models.keyedvectors.Vocab at 0x276eeb64d88>,\n",
       " 'nuclear': <gensim.models.keyedvectors.Vocab at 0x276eeb64dc8>,\n",
       " 'material': <gensim.models.keyedvectors.Vocab at 0x276eeb64e08>,\n",
       " 'lucky': <gensim.models.keyedvectors.Vocab at 0x276eeb64e48>,\n",
       " 'closely': <gensim.models.keyedvectors.Vocab at 0x276eeb64e88>,\n",
       " 'consider': <gensim.models.keyedvectors.Vocab at 0x276eeb64ec8>,\n",
       " 'opportunity': <gensim.models.keyedvectors.Vocab at 0x276eeb64f08>,\n",
       " 'four': <gensim.models.keyedvectors.Vocab at 0x276eeb64f48>,\n",
       " 'milestones': <gensim.models.keyedvectors.Vocab at 0x276eeb64f88>,\n",
       " 'career': <gensim.models.keyedvectors.Vocab at 0x276eeb64fc8>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "words = model.wv.vocab\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.6107758e-03, -4.0217559e-03,  3.7530619e-03, -3.1456298e-03,\n",
       "        8.5410255e-04,  2.9612947e-03,  3.8651116e-03, -3.9985185e-03,\n",
       "       -4.2246790e-03, -4.7475244e-03, -4.9167071e-03,  1.6490809e-03,\n",
       "       -5.5259326e-04,  9.1991073e-04, -4.5176857e-04,  2.9726962e-03,\n",
       "       -8.4810291e-04, -1.7059827e-04, -2.6132581e-03, -3.7822872e-03,\n",
       "        4.1352147e-03, -2.7650199e-03,  3.4308007e-03,  7.1431103e-04,\n",
       "        9.5266465e-04, -5.6538999e-04,  1.8545808e-03,  4.5120870e-03,\n",
       "        7.0129760e-04, -3.5103387e-03,  1.4858623e-03, -1.2473739e-03,\n",
       "       -4.1120560e-03,  3.4754297e-03, -8.7051000e-04, -2.7198375e-03,\n",
       "       -1.1857422e-04,  1.2726682e-03, -2.3436025e-03,  3.0070925e-03,\n",
       "        9.0380106e-04,  4.3416810e-03,  3.9990908e-03,  3.1695541e-03,\n",
       "       -2.3839511e-03,  3.7745791e-03, -2.1570201e-03,  1.2968159e-03,\n",
       "       -2.5486988e-03,  1.4298523e-03, -3.0781659e-05,  1.2500098e-04,\n",
       "        2.2943504e-03, -4.0168087e-03, -4.0070596e-03, -8.1712886e-04,\n",
       "        4.5434791e-03,  2.3978383e-03, -3.8824466e-03, -1.3225125e-03,\n",
       "       -4.2563407e-03, -1.7078149e-03,  2.3678388e-03,  3.4127929e-03,\n",
       "        4.1071945e-03,  4.2101545e-03,  4.7013201e-03, -3.3951604e-03,\n",
       "       -3.3210840e-03, -4.2981324e-03, -4.8284477e-04,  4.7451947e-03,\n",
       "        3.0777873e-03,  4.0006512e-03, -4.5727869e-03,  8.2070573e-04,\n",
       "        2.4431881e-03, -3.8608660e-03,  4.2515225e-03, -4.9968190e-03,\n",
       "        4.1786749e-03,  2.0969708e-03,  3.2019515e-03,  2.3868815e-03,\n",
       "       -1.4793541e-03, -2.0225563e-03,  2.5830010e-03,  1.3994760e-03,\n",
       "        4.8495475e-03, -1.1677359e-04, -3.0539874e-03,  3.0260102e-03,\n",
       "       -4.3486543e-03,  1.2651852e-03, -2.2123894e-03,  4.4271880e-04,\n",
       "        2.3694180e-03, -6.8401452e-04, -4.3194261e-03, -7.5737992e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding Word Vectors\n",
    "vector = model.wv['war']\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most similar words\n",
    "similar = model.wv.most_similar('vikram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('way', 0.21330544352531433),\n",
       " ('succeeded', 0.17867054045200348),\n",
       " ('first', 0.17560702562332153),\n",
       " ('land', 0.17553605139255524),\n",
       " ('lands', 0.16589978337287903),\n",
       " ('us', 0.16570809483528137),\n",
       " ('vision', 0.16152164340019226),\n",
       " ('nation', 0.1482030749320984),\n",
       " ('self-assured', 0.14616546034812927),\n",
       " ('levels', 0.1453283280134201)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for your further study or for your project you can work on like:\n",
    "\n",
    "#### BERT\n",
    "#### Wordembedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
